{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "import imutils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.applications import ResNet50V2, DenseNet121, VGG19, EfficientNetB7, InceptionV3, MobileNetV3Large\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_v2_preprocess_input\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess_input\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_v3_preprocess_input\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input as mobilenet_v3_preprocess_input\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import LSTM, Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, Conv2DTranspose, Reshape, Input, ReLU, LeakyReLU, TimeDistributed\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall, Accuracy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dataset directories \"\"\"\n",
    "dataset_dir = \"filtered_dataset\"\n",
    "# dataset_dir = \"archive/Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get the first image from the healthy directory \"\"\"\n",
    "first_image_file = os.listdir(f\"{dataset_dir}/Not Dementia\")[0]\n",
    "img = plt.imread(f\"{dataset_dir}/Not Dementia/{first_image_file}\")\n",
    "\n",
    "img_height, img_width, _ = img.shape\n",
    "\n",
    "img_size = 224\n",
    "# img_size = min(img_height, img_width)\n",
    "\n",
    "print(f\"Image size: {img_height}x{img_width} -> {img_size}x{img_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General preprocessing and augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Display raw images from different classes \"\"\"\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for i, subdir in enumerate(os.listdir(dataset_dir)):\n",
    "    subdir_path = os.path.join(dataset_dir, subdir)\n",
    "    img_files = os.listdir(subdir_path)[:4]\n",
    "\n",
    "    for j, img_file in enumerate(img_files):\n",
    "        img_path = os.path.join(subdir_path, img_file)\n",
    "        img = plt.imread(img_path)\n",
    "\n",
    "        plt.subplot(4, 4, i * 4 + j + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(subdir)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom preprocessing on Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe(img):\n",
    "    # Convert image to grayscale\n",
    "    grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) for contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    equalized_img = clahe.apply(grayscale_img)\n",
    "\n",
    "    return equalized_img\n",
    "\n",
    "\n",
    "def enhance_sharpness(img):\n",
    "    # Apply Laplacian sharpening to enhance details\n",
    "    laplacian = cv2.Laplacian(img, cv2.CV_8U, ksize=3)\n",
    "\n",
    "    # Add the original image with the sharpened details\n",
    "    sharpened_img = cv2.addWeighted(img, 1.5, laplacian, -0.5, 0)\n",
    "\n",
    "    return sharpened_img\n",
    "\n",
    "\n",
    "def crop_image(img, add_pixels_value=1):\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    gray_blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "    # Thresholding to create a binary image\n",
    "    _, thresh = cv2.threshold(gray_blur, 45, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Morphological operations (erosion and dilation) to remove noise\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Find contours\n",
    "    contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "\n",
    "    # If no contours found, return original image\n",
    "    if len(contours) == 0:\n",
    "        return img\n",
    "\n",
    "    # Get the largest contour\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Get the bounding box of the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "    # Add extra pixels to the bounding box if specified\n",
    "    x -= add_pixels_value\n",
    "    y -= add_pixels_value\n",
    "    w += add_pixels_value * 2\n",
    "    h += add_pixels_value * 2\n",
    "\n",
    "    # Ensure the bounding box coordinates are within image bounds\n",
    "    x = max(x, 0)\n",
    "    y = max(y, 0)\n",
    "    w = min(w, img.shape[1])\n",
    "    h = min(h, img.shape[0])\n",
    "\n",
    "    # Crop the image using the bounding box\n",
    "    cropped_img = img[y : y + h, x : x + w].copy()\n",
    "\n",
    "    return cropped_img\n",
    "\n",
    "\n",
    "def resize_image(img, size):\n",
    "    # Resize the image to the specified size\n",
    "    resized_img = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Change run cell to True if you need the preprocessed images. Then keep toggle as False to only get the final preprocessed images.\n",
    "\"\"\"\n",
    "\n",
    "prep_dir_1 = \"dataset_preprocessed_1_clahe\"\n",
    "prep_dir_2 = \"dataset_preprocessed_2_sharp\"\n",
    "prep_dir_3 = \"dataset_preprocessed_3_crop\"\n",
    "prep_dir_4 = \"dataset_preprocessed_4_final\"\n",
    "\n",
    "# Flag for this cell\n",
    "run_cell = False\n",
    "\n",
    "if run_cell:\n",
    "    # Local save intermediate outputs toggle\n",
    "    toggle = False\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    for prep_dir in [prep_dir_1, prep_dir_2, prep_dir_3, prep_dir_4]:\n",
    "        if not os.path.exists(prep_dir):\n",
    "            os.makedirs(prep_dir)\n",
    "\n",
    "    for subdir in os.listdir(dataset_dir):\n",
    "        subdir_path = os.path.join(dataset_dir, subdir)\n",
    "\n",
    "        # Create subdirectories in each preprocessing directory\n",
    "        for prep_dir in [prep_dir_1, prep_dir_2, prep_dir_3, prep_dir_4]:\n",
    "            new_subdir_path = os.path.join(prep_dir, subdir)\n",
    "            if not os.path.exists(new_subdir_path):\n",
    "                os.makedirs(new_subdir_path)\n",
    "\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            img_path = os.path.join(subdir_path, filename)\n",
    "            img = plt.imread(img_path)\n",
    "\n",
    "            # Apply CLAHE and save the result in prep_dir_1\n",
    "            clahe_img = apply_clahe(img)\n",
    "            new_filename = os.path.join(prep_dir_1, subdir, filename)\n",
    "            if toggle:\n",
    "                plt.imsave(new_filename, clahe_img, cmap=\"gray\")\n",
    "\n",
    "            # Enhance sharpness and save the result in prep_dir_2\n",
    "            sharp_img = enhance_sharpness(clahe_img)\n",
    "            new_filename = os.path.join(prep_dir_2, subdir, filename)\n",
    "            if toggle:\n",
    "                plt.imsave(new_filename, sharp_img, cmap=\"gray\")\n",
    "\n",
    "            # Crop image and save the result in prep_dir_3\n",
    "            cropp_image = crop_image(sharp_img)\n",
    "            new_filename = os.path.join(prep_dir_3, subdir, filename)\n",
    "            if toggle:\n",
    "                plt.imsave(new_filename, cropp_image, cmap=\"gray\")\n",
    "\n",
    "            # Resize image to 224x224 and save the result in prep_dir_4\n",
    "            preprocessed_img = resize_image(cropp_image, img_size)\n",
    "            new_filename = os.path.join(prep_dir_4, subdir, filename)\n",
    "            plt.imsave(new_filename, preprocessed_img, cmap=\"gray\")\n",
    "\n",
    "prep_dir = prep_dir_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_preprocess(img):\n",
    "#     # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) for contrast enhancement\n",
    "#     clahe_img = apply_clahe(img)\n",
    "\n",
    "#     # Enhance sharpness\n",
    "#     sharp_img = enhance_sharpness(clahe_img)\n",
    "\n",
    "#     # Crop image\n",
    "#     cropped_img = crop_image(sharp_img)\n",
    "\n",
    "#     # Resize image to 224x224\n",
    "#     preprocessed_img = resize_image(cropped_img, img_size)\n",
    "\n",
    "#     return preprocessed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Given images are in naming syntax of \"OAS1_0001_MR1_mpr-1_100.jpg\". I want to only keep the images that end between _120.jpg and _140.jpg\n",
    "# pattern = re.compile(r\".*_(12[0-9]|13[0-9]|140).jpg\")\n",
    "\n",
    "# for sub_dir in os.listdir(prep_dir):\n",
    "#     for img_file in os.listdir(f\"{prep_dir}/{sub_dir}\"):\n",
    "#         if not pattern.match(img_file):\n",
    "#             os.remove(f\"{prep_dir}/{sub_dir}/{img_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Display raw images from different classes \"\"\"\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for i, subdir in enumerate(os.listdir(prep_dir)):\n",
    "    subdir_path = os.path.join(prep_dir, subdir)\n",
    "    img_files = os.listdir(subdir_path)[:4]\n",
    "\n",
    "    for j, img_file in enumerate(img_files):\n",
    "        img_path = os.path.join(subdir_path, img_file)\n",
    "        img = plt.imread(img_path)\n",
    "\n",
    "        plt.subplot(4, 4, i * 4 + j + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(subdir)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "epochs_number = 200\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Set early stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=10, min_delta=0.001, restore_best_weights=True)\n",
    "\n",
    "# Set learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=\"val_accuracy\", patience=5, verbose=1, factor=0.75, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    height_shift_range=0.05,\n",
    "    width_shift_range=0.05,\n",
    "    rotation_range=10,\n",
    "    validation_split=0.1,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(prep_dir, target_size=(img_size, img_size), batch_size=batch_size, class_mode=\"categorical\", subset=\"training\", shuffle=True, seed=42)\n",
    "val_generator = val_datagen.flow_from_directory(prep_dir, target_size=(img_size, img_size), batch_size=batch_size, class_mode=\"categorical\", subset=\"validation\", shuffle=False, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some of the training augmented images\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for i in range(16):\n",
    "    img = train_generator[0][0][i]\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display some of the validation augmented images\n",
    "# plt.figure(figsize=(8, 8))\n",
    "\n",
    "# for i in range(16):\n",
    "#     img = val_generator[0][0][i]\n",
    "#     plt.subplot(4, 4, i + 1)\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get class labels \"\"\"\n",
    "class_labels = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Number of classes\"\"\"\n",
    "num_classes = len(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "epochs_number = 200\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Set early stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Set learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1, mode='min', factor=0.75, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CNN architecture\n",
    "custom_CNN_model = Sequential([\n",
    "    Conv2D(64, (3, 3), input_shape=(img_size, img_size, 3)),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(128, (3, 3)),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "custom_CNN_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Show model summary\n",
    "custom_CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "custom_CNN_history = custom_CNN_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs_number, \n",
    "    validation_data=val_generator, \n",
    "    callbacks=[learning_rate_reduction, early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "custom_CNN_model.save(\"models/custom_CNN_model.h5\")\n",
    "\n",
    "# Save history\n",
    "with open(\"models/custom_CNN_history.pkl\", \"wb\") as f:\n",
    "    pkl.dump(custom_CNN_history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "axs[0].plot(custom_CNN_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "axs[0].plot(custom_CNN_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"Training and validation accuracy - Custom CNN\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "axs[1].plot(custom_CNN_history.history[\"loss\"], label=\"Training loss\")\n",
    "axs[1].plot(custom_CNN_history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "axs[1].set_title(\"Training and validation loss - Custom CNN\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EfficientNet-B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "epochs_number = 200\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Set early stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Set learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1, mode='min', factor=0.75, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load the EfficientNet model \"\"\"\n",
    "base_efficientNet_model = EfficientNetB7(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_efficientNet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head and create model\n",
    "efficientNet_model = Sequential([\n",
    "    base_efficientNet_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, kernel_regularizer=L2(0.01), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "efficientNet_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Show model summary\n",
    "efficientNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "efficientNet_history = efficientNet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs_number,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[learning_rate_reduction, early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "axs[0].plot(efficientNet_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "axs[0].plot(efficientNet_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"Training and validation accuracy - EfficientNetB7\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "axs[1].plot(efficientNet_history.history[\"loss\"], label=\"Training loss\")\n",
    "axs[1].plot(efficientNet_history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "axs[1].set_title(\"Training and validation loss - EfficientNetB7\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "efficientNet_model.save(\"models/efficientNet_model.h5\")\n",
    "\n",
    "# Save history\n",
    "with open(\"models/efficientNet_history.pkl\", \"wb\") as f:\n",
    "    pkl.dump(efficientNet_history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. VGG19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "epochs_number = 200\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Set early stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Set learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1, mode='min', factor=0.75, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load the VGG19 model \"\"\"\n",
    "base_vgg_model = VGG19(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head and create model\n",
    "vgg_model = Sequential([\n",
    "    base_vgg_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, kernel_regularizer=L2(0.01), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "vgg_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Show model summary\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "vgg_history = vgg_model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs_number,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[learning_rate_reduction, early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "axs[0].plot(vgg_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "axs[0].plot(vgg_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"Training and validation accuracy - VGG19\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "axs[1].plot(vgg_history.history[\"loss\"], label=\"Training loss\")\n",
    "axs[1].plot(vgg_history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "axs[1].set_title(\"Training and validation loss - VGG19\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "vgg_model.save(\"models/vgg_model.h5\")\n",
    "\n",
    "# Save the history\n",
    "with open(\"models/vgg_history.pkl\", \"wb\") as f:\n",
    "    pkl.dump(vgg_history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ResNet-50 V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "epochs_number = 200\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Set early stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Set learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1, mode='min', factor=0.75, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50V2 model\n",
    "base_resNet_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_resNet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head and create model\n",
    "resnet_model = Sequential([\n",
    "    base_resNet_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, kernel_regularizer=L2(0.01), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "resnet_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Show model summary\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train model \"\"\"\n",
    "resNet_history = resnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs_number,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[learning_rate_reduction, early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "\"\"\" Plot training and validation accuracy \"\"\"\n",
    "axs[0].plot(resNet_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "axs[0].plot(resNet_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"Training and validation accuracy - ResNet50V2\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "axs[0].legend()\n",
    "\n",
    "\"\"\" Plot training and validation loss \"\"\"\n",
    "axs[1].plot(resNet_history.history[\"loss\"], label=\"Training loss\")\n",
    "axs[1].plot(resNet_history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "axs[1].set_title(\"Training and validation loss - ResNet50V2\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Save model \"\"\"\n",
    "resnet_model.save(\"models/resNet_model.h5\")\n",
    "\n",
    "\"\"\" Save history \"\"\"\n",
    "with open(\"models/resNet_history.pkl\", \"wb\") as f:\n",
    "    pkl.dump(resNet_history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DenseNet-121 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "epochs_number = 200\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Set early stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Set learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1, mode='min', factor=0.75, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained DenseNet121 model\n",
    "base_denseNet_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_denseNet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head and create model\n",
    "denseNet_model = Sequential([\n",
    "    base_denseNet_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, kernel_regularizer=L2(0.01), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "denseNet_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Show model summary\n",
    "denseNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train model \"\"\"\n",
    "denseNet_history = denseNet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs_number,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[learning_rate_reduction, early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "axs[0].plot(denseNet_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "axs[0].plot(denseNet_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"Training and validation accuracy - DenseNet121\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "axs[1].plot(denseNet_history.history[\"loss\"], label=\"Training loss\")\n",
    "axs[1].plot(denseNet_history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "axs[1].set_title(\"Training and validation loss - DenseNet121\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "denseNet_model.save(\"models/denseNet_model.h5\")\n",
    "\n",
    "# Save history\n",
    "with open(\"models/denseNet_history.pkl\", \"wb\") as f:\n",
    "    pkl.dump(denseNet_history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inception-V3 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "epochs_number = 200\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Set early stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Set learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1, mode='min', factor=0.75, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load the Inception model \"\"\"\n",
    "base_inception_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_inception_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head and create model\n",
    "inception_model = Sequential([\n",
    "    base_inception_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, kernel_regularizer=L2(0.01), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "inception_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Show model summary\n",
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "inception_history = inception_model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs_number,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[learning_rate_reduction, early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "axs[0].plot(inception_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "axs[0].plot(inception_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"Training and validation accuracy - InceptionV3\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "axs[1].plot(inception_history.history[\"loss\"], label=\"Training loss\")\n",
    "axs[1].plot(inception_history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "axs[1].set_title(\"Training and validation loss - IncetionV3\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "inception_model.save(\"models/inception_model.h5\")\n",
    "\n",
    "# Save history\n",
    "with open(\"models/inception_history.pkl\", \"wb\") as f:\n",
    "    pkl.dump(inception_history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MobileNet model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "epochs_number = 200\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Set early stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Set learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1, mode='min', factor=0.75, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load the MobileNet model \"\"\"\n",
    "base_mobileNet_model = MobileNetV3Large(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_mobileNet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head and create model\n",
    "mobileNet_model = Sequential([\n",
    "    base_mobileNet_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, kernel_regularizer=L2(0.01), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "mobileNet_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Show model summary\n",
    "mobileNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "mobileNet_history = mobileNet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs_number,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[learning_rate_reduction, early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "mobileNet_model.save(\"models/mobileNet_model.h5\")\n",
    "\n",
    "# Save history\n",
    "with open(\"models/mobileNet_history.pkl\", \"wb\") as f:\n",
    "    pkl.dump(mobileNet_history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "axs[0].plot(mobileNet_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "axs[0].plot(mobileNet_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"Training and validation accuracy - MobileNetV3\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "axs[1].plot(mobileNet_history.history[\"loss\"], label=\"Training loss\")\n",
    "axs[1].plot(mobileNet_history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "axs[1].set_title(\"Training and validation loss - MobileNetV3\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table comparing the performance of models\n",
    "resNet_accuracy = resNet_history.history[\"accuracy\"][-1]\n",
    "resNet_val_accuracy = resNet_history.history[\"val_accuracy\"][-1]\n",
    "\n",
    "denseNet_accuracy = denseNet_history.history[\"accuracy\"][-1]\n",
    "denseNet_val_accuracy = denseNet_history.history[\"val_accuracy\"][-1]\n",
    "\n",
    "vgg_accuracy = vgg_history.history[\"accuracy\"][-1]\n",
    "vgg_val_accuracy = vgg_history.history[\"val_accuracy\"][-1]\n",
    "\n",
    "inception_accuracy = inception_history.history[\"accuracy\"][-1]\n",
    "inception_val_accuracy = inception_history.history[\"val_accuracy\"][-1]\n",
    "\n",
    "mobileNet_accuracy = mobileNet_history.history[\"accuracy\"][-1]\n",
    "mobileNet_val_accuracy = mobileNet_history.history[\"val_accuracy\"][-1]\n",
    "\n",
    "efficientNet_accuracy = efficientNet_history.history[\"accuracy\"][-1]\n",
    "efficientNet_val_accuracy = efficientNet_history.history[\"val_accuracy\"][-1]\n",
    "\n",
    "custom_CNN_accuracy = custom_CNN_history.history[\"accuracy\"][-1]\n",
    "custom_CNN_val_accuracy = custom_CNN_history.history[\"val_accuracy\"][-1]\n",
    "\n",
    "model_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\n",
    "            \"ResNet50V2\",\n",
    "            \"DenseNet121\",\n",
    "            \"VGG19\",\n",
    "            \"InceptionV3\",\n",
    "            \"MobileNetV3\",\n",
    "            \"EfficientNetB7\",\n",
    "            \"Custom CNN\"\n",
    "        ],\n",
    "        \"Train Accuracy\": [\n",
    "            resNet_accuracy,\n",
    "            denseNet_accuracy,\n",
    "            vgg_accuracy,\n",
    "            inception_accuracy,\n",
    "            mobileNet_accuracy,\n",
    "            efficientNet_accuracy,\n",
    "            custom_CNN_accuracy,\n",
    "        ],\n",
    "        \"Validation Accuracy\": [\n",
    "            resNet_val_accuracy,\n",
    "            denseNet_val_accuracy,\n",
    "            vgg_val_accuracy,\n",
    "            inception_val_accuracy,\n",
    "            mobileNet_val_accuracy,\n",
    "            efficientNet_val_accuracy,\n",
    "            custom_CNN_val_accuracy,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sort the models by validation accuracy\n",
    "model_comparison = model_comparison.sort_values(by=\"Validation Accuracy\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Model\", y=\"Validation Accuracy\", data=model_comparison, palette=\"viridis\")\n",
    "plt.title(\"Comparison of Validation Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import visualkeras\n",
    "\n",
    "# model = vgg_model\n",
    "\n",
    "# # visualkeras.layered_view(model).show()\n",
    "# # visualkeras.layered_view(model, to_file='output.png')\n",
    "# # visualkeras.layered_view(model, to_file='output.png').show()\n",
    "\n",
    "# visualkeras.layered_view(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
