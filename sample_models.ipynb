{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, AveragePooling2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, Conv2DTranspose, Reshape, Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_dir = \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image size from the first image\n",
    "first_image_file = os.listdir(f\"{dataset_dir}/Non Demented\")[0]\n",
    "img = plt.imread(f\"{dataset_dir}/Non Demented/{first_image_file}\")\n",
    "\n",
    "img_height, img_width, _ = img.shape\n",
    "\n",
    "print(f\"Image size: {img_height}x{img_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tensor image generator to load train-test generators\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(dataset_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode=\"categorical\", subset=\"training\", shuffle=True, seed=42)\n",
    "test_generator = datagen.flow_from_directory(dataset_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode=\"categorical\", subset=\"validation\", shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def crop_image(image):\n",
    "#     \"\"\"Crops the black borders around an image.\"\"\"\n",
    "#     # Convert to grayscale\n",
    "#     gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Threshold the image to get the binary mask\n",
    "#     _, thresholded_image = cv2.threshold(gray_image, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "#     # Find contours\n",
    "#     contours, _ = cv2.findContours(thresholded_image.astype(\"uint8\"), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     # If contours were found, crop the image\n",
    "#     if contours:\n",
    "#         x, y, width, height = cv2.boundingRect(contours[0])\n",
    "#         cropped_image = image[y : y + height, x : x + width]\n",
    "#         return cropped_image\n",
    "\n",
    "#     # If no contours were found, return the original image\n",
    "#     return image\n",
    "\n",
    "\n",
    "# def get_cropped_images(generator, batch_size):\n",
    "#     \"\"\"Returns a new ImageDataGenerator with cropped images and their corresponding labels from a generator.\"\"\"\n",
    "#     cropped_images = []\n",
    "#     labels = []\n",
    "\n",
    "#     # Iterate over all batches in the generator\n",
    "#     for i in range(len(generator)):\n",
    "#         images_batch, labels_batch = generator[i]\n",
    "\n",
    "#         # Iterate over all images in the batch\n",
    "#         for image, label in zip(images_batch, labels_batch):\n",
    "#             cropped_image = crop_image(image)\n",
    "#             cropped_images.append(cropped_image)\n",
    "#             labels.append(label)\n",
    "\n",
    "#     cropped_images = np.array(cropped_images)\n",
    "#     labels = np.array(labels)\n",
    "\n",
    "#     # Create a new ImageDataGenerator with cropped images and labels\n",
    "#     cropped_generator = ImageDataGenerator()\n",
    "#     cropped_generator.fit(cropped_images)\n",
    "\n",
    "#     return cropped_generator.flow(cropped_images, labels, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# # Get the cropped images and labels\n",
    "# train_generator = get_cropped_images(train_generator, batch_size)\n",
    "# test_generator = get_cropped_images(test_generator, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the cropped images\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# axes[0].imshow(X_train[10])\n",
    "# axes[0].set_title(\"Cropped Image\")\n",
    "# axes[1].imshow(train_generator[0][0][10])\n",
    "# axes[1].set_title(\"Original Image\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class labels\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Display sample images\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    for X_batch, Y_batch in train_generator:\n",
    "        image = X_batch[0]\n",
    "        label = Y_batch[0]\n",
    "        plt.imshow(image)\n",
    "        plt.title(class_labels[np.argmax(label)])\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes\n",
    "num_classes = len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "epochs_number = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recall_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     return recall\n",
    "\n",
    "\n",
    "# def precision_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     return precision\n",
    "\n",
    "\n",
    "# def specificity_m(y_true, y_pred):\n",
    "#     true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "#     possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "#     specificity = true_negatives / (possible_negatives + K.epsilon())\n",
    "#     return specificity\n",
    "\n",
    "\n",
    "# def f1_m(y_true, y_pred):\n",
    "#     precision = precision_m(y_true, y_pred)\n",
    "#     recall = recall_m(y_true, y_pred)\n",
    "#     return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "adam_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing pretrained ResNet-50 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ResNet50 model\n",
    "base_resNet_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_resNet_model.output\n",
    "x = AveragePooling2D(pool_size=(4, 4))(x)\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# Create model\n",
    "resnet_model = Model(inputs=base_resNet_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_resNet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "resnet_model.compile(optimizer=adam_optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# resnet_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "resNet_history = resnet_model.fit(\n",
    "    train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=epochs_number, validation_data=test_generator, validation_steps=test_generator.samples // batch_size, callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(resNet_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "plt.plot(resNet_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy - ResNet50V2\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "resnet_model.save(\"resNet_model.h5\")\n",
    "\n",
    "# Save history\n",
    "with open(\"resNet_history.pkl\", \"wb\") as f:\n",
    "    pkl.dump(resNet_history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing DenseNet-121 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained DenseNet121 model\n",
    "base_denseNet_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_denseNet_model.output\n",
    "x = AveragePooling2D(pool_size = (4,4))(x)\n",
    "x = Flatten(name= 'flatten')(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(num_classes, activation = 'softmax')(x)\n",
    "\n",
    "# Create model\n",
    "denseNet_model = Model(inputs=base_denseNet_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_denseNet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "denseNet_model.compile(optimizer=adam_optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# denseNet_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "denseNet_history = denseNet_model.fit(\n",
    "    train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=epochs_number, validation_data=test_generator, validation_steps=test_generator.samples // batch_size, callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(denseNet_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "plt.plot(denseNet_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy - DenseNet121\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "denseNet_model.save(\"denseNet_model.h5\")\n",
    "\n",
    "# Save history\n",
    "with open(\"denseNet_history.pkl\", \"wb\") as f:\n",
    "    pkl.dump(denseNet_history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing EfficientNetB7 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ResNet50 model\n",
    "base_efficientNet_model = EfficientNetB7(weights=\"imagenet\", include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_efficientNet_model.output\n",
    "x = AveragePooling2D(pool_size = (4,4))(x)\n",
    "x = Flatten(name= 'flatten')(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(num_classes, activation = 'softmax')(x)\n",
    "\n",
    "# Create model\n",
    "efficientNet_model = Model(inputs=base_efficientNet_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_efficientNet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "efficientNet_model.compile(optimizer=adam_optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# efficientNet_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "efficientNet_history = efficientNet_model.fit(\n",
    "    train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=epochs_number, validation_data=test_generator, validation_steps=test_generator.samples // batch_size, callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "efficientNet_model.save(\"efficientNet_model.h5\")\n",
    "\n",
    "# Save the history\n",
    "with open(\"efficientNet_history.pkl\", \"wb\") as f:\n",
    "    pkl.dump(efficientNet_history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(efficientNet_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "plt.plot(efficientNet_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy - EfficientNetB7\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing custom CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom CNN architecture\n",
    "# custom_model = Sequential(\n",
    "#     [\n",
    "#         Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_height, img_width, 3)),\n",
    "#         MaxPooling2D((2, 2)),\n",
    "#         Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "#         MaxPooling2D((2, 2)),\n",
    "#         Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "#         MaxPooling2D((2, 2)),\n",
    "#         Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "#         MaxPooling2D((2, 2)),\n",
    "#         Flatten(),\n",
    "#         Dense(512, activation=\"relu\"),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(num_classes, activation=\"softmax\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Compile the model\n",
    "# custom_model.compile(optimizer=adam_optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# # custom_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# custom_CNN_history = custom_model.fit(\n",
    "#     train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=epochs_number, validation_data=test_generator, validation_steps=test_generator.samples // batch_size, callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the trained model\n",
    "# custom_model.save(\"custom_CNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(custom_CNN_history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "# plt.plot(custom_CNN_history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "# plt.title(\"Training and validation accuracy - Custom CNN\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table comparing the performance of models\n",
    "resNet_accuracy = resNet_history.history[\"accuracy\"][-1]\n",
    "resNet_val_accuracy = resNet_history.history[\"val_accuracy\"][-1]\n",
    "denseNet_accuracy = denseNet_history.history[\"accuracy\"][-1]\n",
    "denseNet_val_accuracy = denseNet_history.history[\"val_accuracy\"][-1]\n",
    "efficientNet_accuracy = efficientNet_history.history[\"accuracy\"][-1]\n",
    "efficientNet_val_accuracy = efficientNet_history.history[\"val_accuracy\"][-1]\n",
    "# custom_CNN_accuracy = custom_CNN_history.history[\"accuracy\"][-1]\n",
    "# custom_CNN_val_accuracy = custom_CNN_history.history[\"val_accuracy\"][-1]\n",
    "\n",
    "# resNet_f1 = resNet_history.history[\"f1_m\"][-1]\n",
    "# resNet_val_f1 = resNet_history.history[\"val_f1_m\"][-1]\n",
    "# denseNet_f1 = denseNet_history.history[\"f1_m\"][-1]\n",
    "# denseNet_val_f1 = denseNet_history.history[\"val_f1_m\"][-1]\n",
    "# efficientNet_f1 = efficientNet_history.history[\"f1_m\"][-1]\n",
    "# efficientNet_val_f1 = efficientNet_history.history[\"val_f1_m\"][-1]\n",
    "# custom_CNN_f1 = custom_CNN_history.history[\"f1_m\"][-1]\n",
    "# custom_CNN_val_f1 = custom_CNN_history.history[\"val_f1_m\"][-1]\n",
    "\n",
    "model_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\"ResNet50V2\", \"DenseNet121\", \"Custom CNN\", \"EfficientNetB7\"],\n",
    "        \"Train Accuracy\": [resNet_accuracy, denseNet_accuracy, efficientNet_accuracy],\n",
    "        \"Validation Accuracy\": [resNet_val_accuracy, denseNet_val_accuracy, efficientNet_val_accuracy],\n",
    "        # \"Training F1 Score\": [resNet_f1, denseNet_f1, custom_CNN_f1, efficientNet_f1],\n",
    "        # \"Validation F1 Score\": [resNet_val_f1, denseNet_val_f1, custom_CNN_val_f1, efficientNet_val_f1],\n",
    "    }\n",
    ")\n",
    "\n",
    "model_comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
